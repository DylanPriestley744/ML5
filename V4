=========================================================

import os, glob, random, shutil, zipfile
import numpy as np
import pandas as pd
import cv2
from tqdm.auto import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import KFold   # ← 加这一行
# ----------------------------
# 0. Config
# ----------------------------
SEED = 42
IMG_SIZE = 512
BATCH_SIZE = 2
EPOCHS = 60
LR = 2e-4
FOLDS = 5
THRESH = 0.5

# IMPORTANT:
# submission script uses (pixel > 0) as vessel.
# So for submission: vessel=255, background=0.
INVERT_OUTPUT_MASK = False  # keep False for submission!

# Mild score boost (safe-ish)
USE_GREEN_CLAHE = True

NUM_WORKERS = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

def seed_everything(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)

# ----------------------------
# 1. Locate dataset on Kaggle (folder or zip)
# ----------------------------
def find_dataset_root():
    # Case A: typical Kaggle input folder
    cand = "/kaggle/input/mltask5"
    if os.path.exists(os.path.join(cand, "segmentation", "train", "image")):
        return cand

    # Case B: any kaggle input folder containing segmentation/train/image
    for d in glob.glob("/kaggle/input/*"):
        if os.path.exists(os.path.join(d, "segmentation", "train", "image")):
            return d

    # Case C: zip file provided as input -> extract to working
    zip_cands = []
    for d in glob.glob("/kaggle/input/*"):
        zip_cands += glob.glob(os.path.join(d, "*.zip"))
        zip_cands += glob.glob(os.path.join(d, "**", "*.zip"), recursive=True)

    # prefer zip with task name
    zip_cands_sorted = sorted(zip_cands, key=lambda x: (("vesselsegmentation" not in x.lower()), x))
    for zp in zip_cands_sorted:
        # extract and check
        out_dir = "/kaggle/working/_dataset_extracted"
        os.makedirs(out_dir, exist_ok=True)
        try:
            with zipfile.ZipFile(zp, "r") as z:
                # quick check members
                names = z.namelist()
                hit = any("segmentation/train/image" in n.replace("\\", "/") for n in names)
                if hit:
                    print("Extracting:", zp)
                    z.extractall(out_dir)
                    # find extracted root that contains segmentation
                    # sometimes zip already has a top folder
                    if os.path.exists(os.path.join(out_dir, "segmentation", "train", "image")):
                        return out_dir
                    for sub in glob.glob(out_dir + "/*"):
                        if os.path.exists(os.path.join(sub, "segmentation", "train", "image")):
                            return sub
        except:
            pass

    return None

DATASET_DIR = find_dataset_root()
assert DATASET_DIR is not None, "找不到数据集。请确认 Kaggle Input 内含 segmentation/ 或提供 zip。"

SEG_ROOT = os.path.join(DATASET_DIR, "segmentation")
TRAIN_IMG_DIR = os.path.join(SEG_ROOT, "train", "image")
TRAIN_MSK_DIR = os.path.join(SEG_ROOT, "train", "label")
TEST_IMG_DIR  = os.path.join(SEG_ROOT, "test",  "image")

print("DATASET_DIR   :", DATASET_DIR)
print("TRAIN_IMG_DIR :", TRAIN_IMG_DIR)
print("TRAIN_MSK_DIR :", TRAIN_MSK_DIR)
print("TEST_IMG_DIR  :", TEST_IMG_DIR)

assert os.path.exists(TRAIN_IMG_DIR), "TRAIN_IMG_DIR 不存在"
assert os.path.exists(TRAIN_MSK_DIR), "TRAIN_MSK_DIR 不存在"
assert os.path.exists(TEST_IMG_DIR),  "TEST_IMG_DIR 不存在"

# locate official script
script_cands = glob.glob(os.path.join(DATASET_DIR, "**", "segmentation_to_csv.py"), recursive=True)
SCRIPT_PATH = script_cands[0] if len(script_cands) > 0 else None
print("SCRIPT_PATH:", SCRIPT_PATH)

# ----------------------------
# 2. File list
# ----------------------------
def sort_key(p):
    b = os.path.splitext(os.path.basename(p))[0]
    return int(b) if b.isdigit() else b

train_images = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, "*.*")), key=sort_key)
train_masks  = sorted(glob.glob(os.path.join(TRAIN_MSK_DIR, "*.*")), key=sort_key)
test_images  = sorted(glob.glob(os.path.join(TEST_IMG_DIR,  "*.*")), key=sort_key)

assert len(train_images) == len(train_masks), "train image/mask 数量不匹配"
print(f"train: {len(train_images)}  test: {len(test_images)}")

# ----------------------------
# 3. Dataset + augment (+ optional CLAHE)
# ----------------------------
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)
IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)

CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

def fundus_preprocess_rgb(img_rgb):
    # keep RGB; only enhance green channel (less domain break than [g,g,g])
    if not USE_GREEN_CLAHE:
        return img_rgb
    out = img_rgb.copy()
    out[:, :, 1] = CLAHE.apply(out[:, :, 1])
    return out

def random_augment(img, msk):
    if random.random() < 0.5:
        img = img[:, ::-1, :]
        msk = msk[:, ::-1]
    if random.random() < 0.5:
        img = img[::-1, :, :]
        msk = msk[::-1, :]

    k = random.randint(0, 3)
    if k:
        img = np.rot90(img, k).copy()
        msk = np.rot90(msk, k).copy()

    if random.random() < 0.5:
        alpha = 1.0 + (random.random() * 0.4 - 0.2)  # 0.8~1.2
        beta  = random.randint(-15, 15)
        img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

    return img, msk

class FundusSegDataset(Dataset):
    def __init__(self, img_paths, msk_paths=None, augment=False):
        self.img_paths = img_paths
        self.msk_paths = msk_paths
        self.augment = augment

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)

        img = fundus_preprocess_rgb(img)

        if self.msk_paths is not None:
            msk_path = self.msk_paths[idx]
            msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)
            msk = cv2.resize(msk, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)

            if self.augment:
                img, msk = random_augment(img, msk)

            # binarize (jpg label may contain gray levels)
            msk = (msk > 127).astype(np.float32)

            img = img.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))

            return torch.tensor(img, dtype=torch.float32), torch.tensor(msk[None, ...], dtype=torch.float32)
        else:
            img = img.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))
            return torch.tensor(img, dtype=torch.float32), os.path.basename(img_path)

# ----------------------------
# 4. UNet (same as your v1)
# ----------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )
    def forward(self, x):
        return self.net(x)

class Down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.pool = nn.MaxPool2d(2)
        self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x):
        return self.conv(self.pool(x))

class Up(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False)
        self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size(2) - x1.size(2)
        diffX = x2.size(3) - x1.size(3)
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, in_ch=3, out_ch=1, base=32):
        super().__init__()
        self.inc = DoubleConv(in_ch, base)
        self.down1 = Down(base, base*2)
        self.down2 = Down(base*2, base*4)
        self.down3 = Down(base*4, base*8)
        self.down4 = Down(base*8, base*16)

        self.up1 = Up(base*16 + base*8, base*8)
        self.up2 = Up(base*8 + base*4, base*4)
        self.up3 = Up(base*4 + base*2, base*2)
        self.up4 = Up(base*2 + base, base)

        self.outc = nn.Conv2d(base, out_ch, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        x = self.up1(x5, x4)
        x = self.up2(x,  x3)
        x = self.up3(x,  x2)
        x = self.up4(x,  x1)
        return self.outc(x)

# ----------------------------
# 5. Loss & metric (same spirit as v1)
# ----------------------------
bce = nn.BCEWithLogitsLoss()

def soft_dice_loss_with_logits(logits, targets, eps=1e-6):
    probs = torch.sigmoid(logits)
    targets = targets.float()
    inter = (probs * targets).sum(dim=(2,3))
    union = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)
    return 1 - dice.mean()

@torch.no_grad()
def dice_coeff_from_logits(logits, targets, thr=0.5, eps=1e-6):
    probs = torch.sigmoid(logits)
    pred = (probs > thr).float()
    gt = (targets > 0.5).float()
    inter = (pred * gt).sum(dim=(2,3))
    union = pred.sum(dim=(2,3)) + gt.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)
    return dice.mean().item()

# ----------------------------
# 6. Train / Val loop
# ----------------------------
def train_one_epoch(model, loader, optimizer, scaler=None):
    model.train()
    total_loss = 0.0
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)
        optimizer.zero_grad(set_to_none=True)

        if scaler is not None:
            with torch.cuda.amp.autocast():
                logits = model(imgs)
                loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            logits = model(imgs)
            loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
            loss.backward()
            optimizer.step()

        total_loss += loss.item() * imgs.size(0)
    return total_loss / len(loader.dataset)

@torch.no_grad()
def validate(model, loader, thr=0.5):
    model.eval()
    total_loss = 0.0
    dices = []
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)
        logits = model(imgs)
        loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
        total_loss += loss.item() * imgs.size(0)
        dices.append(dice_coeff_from_logits(logits, masks, thr=thr))
    return total_loss / len(loader.dataset), float(np.mean(dices))

# ----------------------------
# 7. K-Fold training (v1 style)
# ----------------------------
kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)
fold_models = []

use_amp = torch.cuda.is_available()
print("AMP:", use_amp)

for fold, (tr_idx, va_idx) in enumerate(kf.split(train_images), 1):
    print(f"\n========== Fold {fold}/{FOLDS} ==========")
    tr_imgs = [train_images[i] for i in tr_idx]
    tr_msks = [train_masks[i]  for i in tr_idx]
    va_imgs = [train_images[i] for i in va_idx]
    va_msks = [train_masks[i]  for i in va_idx]

    train_ds = FundusSegDataset(tr_imgs, tr_msks, augment=True)
    val_ds   = FundusSegDataset(va_imgs, va_msks, augment=False)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

    model = UNet(base=32).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    scaler = torch.cuda.amp.GradScaler() if use_amp else None

    best_dice = -1.0
    best_path = f"/kaggle/working/unet_fold{fold}.pt"

    for epoch in range(1, EPOCHS+1):
        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler)
        va_loss, va_dice = validate(model, val_loader, thr=0.5)  # keep 0.5 for model selection
        scheduler.step()

        if va_dice > best_dice:
            best_dice = va_dice
            torch.save(model.state_dict(), best_path)

        if epoch % 10 == 0 or epoch == 1:
            print(f"Epoch {epoch:03d} | tr_loss {tr_loss:.4f} | va_loss {va_loss:.4f} | va_dice {va_dice:.4f} | best {best_dice:.4f}")

    fold_models.append(best_path)

print("\nBest models:", fold_models)

# ----------------------------
# 8. Inference (ensemble + simple TTA) (v1 style)
# ----------------------------
@torch.no_grad()
def predict_with_tta(model, imgs):
    model.eval()
    p0 = torch.sigmoid(model(imgs))

    p1 = torch.sigmoid(model(torch.flip(imgs, dims=[3])))
    p1 = torch.flip(p1, dims=[3])

    p2 = torch.sigmoid(model(torch.flip(imgs, dims=[2])))
    p2 = torch.flip(p2, dims=[2])

    p3 = torch.sigmoid(model(torch.flip(imgs, dims=[2,3])))
    p3 = torch.flip(p3, dims=[2,3])

    return (p0 + p1 + p2 + p3) / 4.0

test_ds = FundusSegDataset(test_images, msk_paths=None, augment=False)
test_loader = DataLoader(test_ds, batch_size=2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

prob_dict = {}

for model_path in fold_models:
    model = UNet(base=32).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    for imgs, names in tqdm(test_loader, desc=f"Predict {os.path.basename(model_path)}"):
        imgs = imgs.to(device)
        probs = predict_with_tta(model, imgs).detach().cpu().numpy()  # (B,1,H,W)
        for i, n in enumerate(names):
            prob_dict[n] = prob_dict.get(n, 0.0) + probs[i, 0]

for n in prob_dict:
    prob_dict[n] /= len(fold_models)

# ----------------------------
# 9. Save predicted masks to ./image  (CRITICAL: clear dir + PNG only)
# ----------------------------
out_img_dir = "/kaggle/working/image"
os.makedirs(out_img_dir, exist_ok=True)

# clear old files to avoid duplicate Id
for p in glob.glob(out_img_dir + "/*"):
    try:
        os.remove(p)
    except:
        pass

SAVE_EXT = "png"  # FORCE PNG (avoid JPG compression noise!)
print("Saving masks as:", SAVE_EXT, "| THRESH:", THRESH)

for img_path in test_images:
    name = os.path.basename(img_path)  # e.g. 1.jpg
    stem = os.path.splitext(name)[0]
    prob = prob_dict[name]

    # submission-safe: vessel=255, background=0
    mask = (prob > THRESH).astype(np.uint8) * 255
    if INVERT_OUTPUT_MASK:
        mask = 255 - mask  # do NOT use for submission

    save_path = os.path.join(out_img_dir, f"{stem}.{SAVE_EXT}")
    cv2.imwrite(save_path, mask)

print("Saved predicted masks to:", out_img_dir)
print("Example saved files:", sorted(glob.glob(out_img_dir + "/*.png"))[:5])

# ----------------------------
# 10. Make submission.csv (prefer official script; fallback to custom RLE)
# ----------------------------
def rle_encode_from_mask_binary(mask_01):
    dots = np.where(mask_01.flatten() == 1)[0]
    if len(dots) == 0:
        return ""
    run_lengths = []
    prev = -2
    for b in dots:
        if b > prev + 1:
            run_lengths.extend((b + 1, 0))  # 1-indexed
        run_lengths[-1] += 1
        prev = b
    return " ".join(map(str, run_lengths))

submission_path = "/kaggle/working/submission.csv"

ok = False
if SCRIPT_PATH is not None and os.path.exists(SCRIPT_PATH):
    try:
        shutil.copy(SCRIPT_PATH, "/kaggle/working/segmentation_to_csv.py")
        ret = os.system("cd /kaggle/working && python segmentation_to_csv.py")
        if ret == 0 and os.path.exists(submission_path):
            ok = True
            print("Official script generated submission.csv ✅")
        else:
            print("Official script did not produce submission.csv -> fallback RLE")
    except Exception as e:
        print("Official script failed -> fallback RLE. Error:", e)

if not ok:
    print("Using custom RLE to generate submission.csv ...")
    rows = []
    pred_files = sorted(glob.glob(out_img_dir + "/*.png"), key=sort_key)
    for p in pred_files:
        stem = os.path.splitext(os.path.basename(p))[0]
        m = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
        m = cv2.resize(m, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
        m01 = (m > 0).astype(np.uint8)  # >0 treated as vessel (same as official)
        rows.append([stem, rle_encode_from_mask_binary(m01)])

    df = pd.DataFrame(rows, columns=["Id", "Predicted"])
    df.to_csv(submission_path, index=False)
    print("Custom submission.csv generated ✅")

# Sanity checks (avoid upload errors)
df = pd.read_csv(submission_path)
print("\nsubmission rows:", len(df), "| unique Id:", df["Id"].nunique())
assert df["Id"].is_unique, "Id 重复：检查 /kaggle/working/image 是否有同名多文件"
assert df["Id"].nunique() == len(test_images), "submission Id 数量与测试图数量不一致"
print(df.head())

print("\nDone! Submit:", submission_path)
