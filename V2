# ============================================================
# Task-5 Vessel Segmentation (Fundus)
# Kaggle-ready: K-Fold UNet -> Ensemble + TTA -> Save masks -> submission.csv (RLE)
#
# Improvements vs baseline:
# 1) Fundus-friendly preprocessing: Green channel + CLAHE
# 2) Better imbalance loss: BCE + Focal-Tversky
# 3) OOF threshold search (global best THRESH) after training
# 4) FOV (field-of-view) mask to suppress false positives outside retina
# 5) Validation Dice computed correctly (sample-weighted)
# ============================================================

import os, glob, random, shutil
import numpy as np
import pandas as pd
import cv2
from tqdm.auto import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from sklearn.model_selection import KFold

# ----------------------------
# 0. Config
# ----------------------------
SEED = 42
IMG_SIZE = 512
BATCH_SIZE = 2
EPOCHS = 80          # small data: allow early stop
PATIENCE = 15        # early stopping patience
LR = 2e-4
FOLDS = 5
THRESH = 0.5         # will be replaced by OOF best threshold
NUM_WORKERS = 2

# IMPORTANT:
# Official RLE script treats (mask > 0) as vessel.
# So for submission: vessel=255, background=0. Do NOT invert for submission.
INVERT_OUTPUT_MASK = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

def seed_everything(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)

# ----------------------------
# 1. Find dataset root (Kaggle Input)
#    Expected:
#      <DATASET_DIR>/segmentation/train/image
#      <DATASET_DIR>/segmentation/train/label
#      <DATASET_DIR>/segmentation/test/image
# ----------------------------
def find_dataset_dir(preferred="/kaggle/input/mltask5"):
    if os.path.exists(os.path.join(preferred, "segmentation", "train", "image")):
        return preferred

    # try scan all kaggle inputs
    cands = glob.glob("/kaggle/input/*")
    for d in cands:
        if os.path.exists(os.path.join(d, "segmentation", "train", "image")):
            return d

    # last resort: recursive search for segmentation/train/image
    for d in cands:
        hits = glob.glob(os.path.join(d, "**", "segmentation", "train", "image"), recursive=True)
        if len(hits) > 0:
            return os.path.abspath(os.path.join(hits[0], "..", "..", ".."))

    return None

DATASET_DIR = find_dataset_dir()
assert DATASET_DIR is not None, "未找到数据集目录：请确认 Kaggle Input 下包含 segmentation/train/image"
print("DATASET_DIR:", DATASET_DIR)

SEG_ROOT = os.path.join(DATASET_DIR, "segmentation")
TRAIN_IMG_DIR = os.path.join(SEG_ROOT, "train", "image")
TRAIN_MSK_DIR = os.path.join(SEG_ROOT, "train", "label")
TEST_IMG_DIR  = os.path.join(SEG_ROOT, "test",  "image")

assert os.path.exists(TRAIN_IMG_DIR), "TRAIN_IMG_DIR 不存在"
assert os.path.exists(TRAIN_MSK_DIR), "TRAIN_MSK_DIR 不存在"
assert os.path.exists(TEST_IMG_DIR),  "TEST_IMG_DIR 不存在"

# find official script
script_cands = glob.glob(os.path.join(DATASET_DIR, "**", "segmentation_to_csv.py"), recursive=True)
SCRIPT_PATH = script_cands[0] if len(script_cands) > 0 else None
print("SCRIPT_PATH:", SCRIPT_PATH)

# ----------------------------
# 2. File list
# ----------------------------
def sort_key(p):
    b = os.path.splitext(os.path.basename(p))[0]
    return int(b) if b.isdigit() else b

train_images = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, "*.*")), key=sort_key)
train_masks  = sorted(glob.glob(os.path.join(TRAIN_MSK_DIR, "*.*")), key=sort_key)
test_images  = sorted(glob.glob(os.path.join(TEST_IMG_DIR,  "*.*")), key=sort_key)

assert len(train_images) == len(train_masks), "train image/mask 数量不匹配"
print(f"train: {len(train_images)}  test: {len(test_images)}")

# ----------------------------
# 3. Preprocess / Augment
# ----------------------------
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)
IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)

CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

def fundus_preprocess_rgb(img_rgb):
    """
    Fundus vessel-friendly preprocess:
    - Use green channel (best vessel contrast)
    - CLAHE enhance local contrast
    Return 3-channel image to keep model unchanged.
    """
    g = img_rgb[:, :, 1]
    g = CLAHE.apply(g)
    out = np.stack([g, g, g], axis=2)
    return out

def random_gamma(img, gamma_range=(0.7, 1.5)):
    gamma = random.uniform(*gamma_range)
    table = (np.linspace(0, 1, 256) ** gamma * 255.0).astype(np.uint8)
    return cv2.LUT(img, table)

def random_augment(img, msk):
    # flips
    if random.random() < 0.5:
        img = img[:, ::-1, :]
        msk = msk[:, ::-1]
    if random.random() < 0.5:
        img = img[::-1, :, :]
        msk = msk[::-1, :]

    # rotate 0/90/180/270
    k = random.randint(0, 3)
    if k:
        img = np.rot90(img, k).copy()
        msk = np.rot90(msk, k).copy()

    # brightness/contrast
    if random.random() < 0.5:
        alpha = 1.0 + (random.random() * 0.4 - 0.2)  # 0.8~1.2
        beta  = random.randint(-15, 15)
        img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

    # gamma (often helps fundus)
    if random.random() < 0.5:
        img = random_gamma(img)

    return img, msk

def make_fov_mask_from_rgb(img_rgb, size=512):
    """
    Quick FOV mask for fundus:
    - threshold on grayscale to get circular retina region
    - close + median to smooth
    Returns 0/1 mask at (size,size)
    """
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)
    gray = cv2.resize(gray, (size, size), interpolation=cv2.INTER_AREA)
    _, m = cv2.threshold(gray, 15, 255, cv2.THRESH_BINARY)
    m = cv2.medianBlur(m, 7)
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, k)
    return (m > 0).astype(np.uint8)

# ----------------------------
# 4. Dataset
# ----------------------------
class FundusSegDataset(Dataset):
    def __init__(self, img_paths, msk_paths=None, augment=False, return_raw_rgb=False):
        self.img_paths = img_paths
        self.msk_paths = msk_paths
        self.augment = augment
        self.return_raw_rgb = return_raw_rgb  # for optional debug

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]

        img_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        # resize first
        img_rgb = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)

        # preprocess (green + clahe)
        img_rgb = fundus_preprocess_rgb(img_rgb)

        if self.msk_paths is not None:
            msk_path = self.msk_paths[idx]
            msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)
            msk = cv2.resize(msk, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)

            if self.augment:
                img_rgb, msk = random_augment(img_rgb, msk)

            # jpg label may have compression gray, binarize
            msk = (msk > 127).astype(np.float32)

            # normalize image
            img = img_rgb.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))  # CHW

            if self.return_raw_rgb:
                return torch.tensor(img, dtype=torch.float32), torch.tensor(msk[None, ...], dtype=torch.float32), img_rgb
            return torch.tensor(img, dtype=torch.float32), torch.tensor(msk[None, ...], dtype=torch.float32)

        else:
            img = img_rgb.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))
            return torch.tensor(img, dtype=torch.float32), os.path.basename(img_path)

# ----------------------------
# 5. UNet (pure torch)
# ----------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )
    def forward(self, x):
        return self.net(x)

class Down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.pool = nn.MaxPool2d(2)
        self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x):
        return self.conv(self.pool(x))

class Up(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False)
        self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size(2) - x1.size(2)
        diffX = x2.size(3) - x1.size(3)
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, in_ch=3, out_ch=1, base=32):
        super().__init__()
        self.inc = DoubleConv(in_ch, base)
        self.down1 = Down(base, base*2)
        self.down2 = Down(base*2, base*4)
        self.down3 = Down(base*4, base*8)
        self.down4 = Down(base*8, base*16)

        self.up1 = Up(base*16 + base*8, base*8)
        self.up2 = Up(base*8 + base*4, base*4)
        self.up3 = Up(base*4 + base*2, base*2)
        self.up4 = Up(base*2 + base, base)

        self.outc = nn.Conv2d(base, out_ch, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        x = self.up1(x5, x4)
        x = self.up2(x,  x3)
        x = self.up3(x,  x2)
        x = self.up4(x,  x1)
        return self.outc(x)

# ----------------------------
# 6. Loss & metric
# ----------------------------
bce = nn.BCEWithLogitsLoss()

def focal_tversky_loss_with_logits(logits, targets, alpha=0.7, beta=0.3, gamma=0.75, eps=1e-6):
    probs = torch.sigmoid(logits)
    targets = targets.float()
    tp = (probs * targets).sum(dim=(2,3))
    fp = (probs * (1 - targets)).sum(dim=(2,3))
    fn = ((1 - probs) * targets).sum(dim=(2,3))
    tversky = (tp + eps) / (tp + alpha * fp + beta * fn + eps)
    loss = (1 - tversky) ** gamma
    return loss.mean()

@torch.no_grad()
def dice_per_sample_from_logits(logits, targets, thr=0.5, eps=1e-6):
    probs = torch.sigmoid(logits)
    pred = (probs > thr).float()
    gt = (targets > 0.5).float()
    inter = (pred * gt).sum(dim=(2,3))
    union = pred.sum(dim=(2,3)) + gt.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)   # (B,1)
    return dice.squeeze(1)                   # (B,)

# ----------------------------
# 7. Train / Val loop (with early stopping)
# ----------------------------
def train_one_epoch(model, loader, optimizer, scaler=None):
    model.train()
    total_loss = 0.0
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)

        optimizer.zero_grad(set_to_none=True)

        if scaler is not None:
            with torch.cuda.amp.autocast():
                logits = model(imgs)
                loss = 0.2*bce(logits, masks) + 0.8*focal_tversky_loss_with_logits(logits, masks)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            logits = model(imgs)
            loss = 0.2*bce(logits, masks) + 0.8*focal_tversky_loss_with_logits(logits, masks)
            loss.backward()
            optimizer.step()

        total_loss += loss.item() * imgs.size(0)

    return total_loss / len(loader.dataset)

@torch.no_grad()
def validate(model, loader, thr=0.5):
    model.eval()
    total_loss = 0.0
    dice_sum = 0.0
    n = 0
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)

        logits = model(imgs)
        loss = 0.2*bce(logits, masks) + 0.8*focal_tversky_loss_with_logits(logits, masks)
        total_loss += loss.item() * imgs.size(0)

        dice_vec = dice_per_sample_from_logits(logits, masks, thr=thr)
        dice_sum += dice_vec.sum().item()
        n += imgs.size(0)

    return total_loss / len(loader.dataset), dice_sum / max(n, 1)

# ----------------------------
# 8. K-Fold training
# ----------------------------
kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)
fold_models = []

use_amp = torch.cuda.is_available()
print("AMP:", use_amp)

for fold, (tr_idx, va_idx) in enumerate(kf.split(train_images), 1):
    print(f"\n========== Fold {fold}/{FOLDS} ==========")
    tr_imgs = [train_images[i] for i in tr_idx]
    tr_msks = [train_masks[i]  for i in tr_idx]
    va_imgs = [train_images[i] for i in va_idx]
    va_msks = [train_masks[i]  for i in va_idx]

    train_ds = FundusSegDataset(tr_imgs, tr_msks, augment=True)
    val_ds   = FundusSegDataset(va_imgs, va_msks, augment=False)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,
                              num_workers=NUM_WORKERS, pin_memory=True, drop_last=False)
    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,
                              num_workers=NUM_WORKERS, pin_memory=True, drop_last=False)

    model = UNet(base=32).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

    scaler = torch.cuda.amp.GradScaler() if use_amp else None

    best_dice = -1.0
    best_path = f"/kaggle/working/unet_fold{fold}.pt"
    bad_epochs = 0

    for epoch in range(1, EPOCHS+1):
        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler)
        va_loss, va_dice = validate(model, val_loader, thr=0.5)
        scheduler.step()

        if va_dice > best_dice + 1e-6:
            best_dice = va_dice
            torch.save(model.state_dict(), best_path)
            bad_epochs = 0
        else:
            bad_epochs += 1

        if epoch % 10 == 0 or epoch == 1:
            print(f"Epoch {epoch:03d} | tr_loss {tr_loss:.4f} | va_loss {va_loss:.4f} | va_dice {va_dice:.4f} | best {best_dice:.4f} | bad {bad_epochs}")

        if bad_epochs >= PATIENCE:
            print(f"Early stopping at epoch {epoch} (patience={PATIENCE}). Best dice={best_dice:.4f}")
            break

    fold_models.append(best_path)

print("\nBest models:", fold_models)

# ----------------------------
# 9. OOF threshold search (global best THRESH)
# ----------------------------
@torch.no_grad()
def predict_probs_single(model, loader):
    model.eval()
    probs_list, tgts_list = [], []
    for imgs, masks in loader:
        imgs = imgs.to(device)
        logits = model(imgs)
        probs = torch.sigmoid(logits).cpu().numpy()[:,0]  # (B,H,W)
        probs_list.append(probs)
        tgts_list.append(masks.numpy()[:,0])
    return np.concatenate(probs_list, 0), np.concatenate(tgts_list, 0)

def dice_np(pred01, gt01, eps=1e-6):
    inter = (pred01 & gt01).sum(axis=(1,2))
    union = pred01.sum(axis=(1,2)) + gt01.sum(axis=(1,2))
    return float(((2*inter + eps) / (union + eps)).mean())

print("\nOOF threshold search ...")
all_oof_probs = []
all_oof_gts   = []

kf2 = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)
for fold, (tr_idx, va_idx) in enumerate(kf2.split(train_images), 1):
    va_imgs = [train_images[i] for i in va_idx]
    va_msks = [train_masks[i]  for i in va_idx]
    val_ds   = FundusSegDataset(va_imgs, va_msks, augment=False)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,
                            num_workers=NUM_WORKERS, pin_memory=True)

    model = UNet(base=32).to(device)
    model.load_state_dict(torch.load(fold_models[fold-1], map_location=device))
    probs, gts = predict_probs_single(model, val_loader)

    all_oof_probs.append(probs)
    all_oof_gts.append(gts)

all_oof_probs = np.concatenate(all_oof_probs, 0)
all_oof_gts   = np.concatenate(all_oof_gts, 0)

best_t, best_d = 0.5, -1
for t in np.linspace(0.20, 0.80, 61):
    pred01 = (all_oof_probs > t).astype(np.uint8)
    gt01   = (all_oof_gts > 0.5).astype(np.uint8)
    d = dice_np(pred01, gt01)
    if d > best_d:
        best_d, best_t = d, float(t)

THRESH = best_t
print(f"OOF best THRESH = {THRESH:.3f}, OOF dice = {best_d:.4f}")

# ----------------------------
# 10. Inference (ensemble + simple TTA)
# ----------------------------
@torch.no_grad()
def predict_with_tta(model, imgs):
    model.eval()
    p0 = torch.sigmoid(model(imgs))

    p1 = torch.sigmoid(model(torch.flip(imgs, dims=[3])))
    p1 = torch.flip(p1, dims=[3])

    p2 = torch.sigmoid(model(torch.flip(imgs, dims=[2])))
    p2 = torch.flip(p2, dims=[2])

    p3 = torch.sigmoid(model(torch.flip(imgs, dims=[2,3])))
    p3 = torch.flip(p3, dims=[2,3])

    return (p0 + p1 + p2 + p3) / 4.0

test_ds = FundusSegDataset(test_images, msk_paths=None, augment=False)
test_loader = DataLoader(test_ds, batch_size=2, shuffle=False,
                         num_workers=NUM_WORKERS, pin_memory=True)

prob_dict = {}  # name -> sum probs

for model_path in fold_models:
    model = UNet(base=32).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    for imgs, names in tqdm(test_loader, desc=f"Predict {os.path.basename(model_path)}"):
        imgs = imgs.to(device)
        probs = predict_with_tta(model, imgs).detach().cpu().numpy()  # (B,1,H,W)
        for i, n in enumerate(names):
            if n not in prob_dict:
                prob_dict[n] = probs[i,0]
            else:
                prob_dict[n] += probs[i,0]

for n in prob_dict:
    prob_dict[n] /= len(fold_models)

# ----------------------------
# 11. Save predicted masks to ./image (for official script)
#     + Apply FOV mask suppression
#     Save BOTH .png and .jpg to be robust to script glob suffix.
# ----------------------------
out_img_dir = "/kaggle/working/image"
os.makedirs(out_img_dir, exist_ok=True)

for img_path in test_images:
    name = os.path.basename(img_path)         # e.g. 1.jpg
    stem = os.path.splitext(name)[0]

    prob = prob_dict[name]                    # (H,W) in 512
    # FOV from original image
    img0 = cv2.imread(img_path, cv2.IMREAD_COLOR)
    img0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)
    fov = make_fov_mask_from_rgb(img0, IMG_SIZE)  # 0/1

    mask01 = (prob > THRESH).astype(np.uint8)
    mask01 = mask01 * fov                          # suppress outside retina
    mask = mask01 * 255                            # vessel=255, background=0

    if INVERT_OUTPUT_MASK:
        # DO NOT use this for official submission (it will invert vessels/background)
        mask = 255 - mask

    save_png = os.path.join(out_img_dir, f"{stem}.png")
    save_jpg = os.path.join(out_img_dir, f"{stem}.jpg")
    cv2.imwrite(save_png, mask)
    cv2.imwrite(save_jpg, mask, [int(cv2.IMWRITE_JPEG_QUALITY), 95])

print("Saved predicted masks to:", out_img_dir)
print("Example saved files:", sorted(glob.glob(out_img_dir+"/*.*"))[:6])

# ----------------------------
# 12. Make submission.csv (prefer official script; fallback to custom RLE)
# ----------------------------
def rle_encode_from_mask_binary(mask_01):
    # mask_01: HxW, values in {0,1}, flatten row-major
    dots = np.where(mask_01.flatten() == 1)[0]
    if len(dots) == 0:
        return ""
    run_lengths = []
    prev = -2
    for b in dots:
        if b > prev + 1:
            run_lengths.extend((b + 1, 0))  # 1-indexed
        run_lengths[-1] += 1
        prev = b
    return " ".join(map(str, run_lengths))

submission_path = "/kaggle/working/submission.csv"
ok = False

if SCRIPT_PATH is not None and os.path.exists(SCRIPT_PATH):
    try:
        shutil.copy(SCRIPT_PATH, "/kaggle/working/segmentation_to_csv.py")
        # run official script (it should read ./image and write submission.csv)
        ret = os.system("cd /kaggle/working && python segmentation_to_csv.py")
        if ret == 0 and os.path.exists("/kaggle/working/submission.csv"):
            ok = True
            print("Official script generated submission.csv ✅")
        else:
            print("Official script executed but submission.csv not found. Fallback to custom RLE.")
    except Exception as e:
        print("Official script failed. Fallback to custom RLE. Error:", e)

if not ok:
    print("Using custom RLE to generate submission.csv ...")
    rows = []
    # read png first; if none, read jpg
    pred_files = sorted(glob.glob(out_img_dir+"/*.png"), key=sort_key)
    if len(pred_files) == 0:
        pred_files = sorted(glob.glob(out_img_dir+"/*.jpg"), key=sort_key)

    for p in pred_files:
        stem = os.path.splitext(os.path.basename(p))[0]
        m = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
        m = cv2.resize(m, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
        m01 = (m > 0).astype(np.uint8)  # >0 as vessel (same as official)
        pred = rle_encode_from_mask_binary(m01)
        rows.append([stem, pred])

    df = pd.DataFrame(rows, columns=["Id", "Predicted"])
    df.to_csv(submission_path, index=False)
    print("Custom submission.csv generated ✅")

print("\nDone! You can submit:", submission_path)
print(pd.read_csv(submission_path).head())

# ----------------------------
# Quick sanity note:
# For submission, masks MUST be vessel=255 (non-zero), background=0.
# Keep INVERT_OUTPUT_MASK=False for Kaggle scoring.
# ----------------------------
