# ============================================================
# Task-5 Vessel Segmentation (Fundus)
# Train UNet -> Predict -> Save masks -> Make submission.csv (RLE)
# Works on Kaggle (no extra ops required)
# ============================================================

import os, glob, zipfile, random
import numpy as np
import pandas as pd
import cv2
from tqdm.auto import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# ----------------------------
# 0. Config
# ----------------------------
SEED = 42
IMG_SIZE = 512
BATCH_SIZE = 2
EPOCHS = 60
LR = 2e-4
FOLDS = 5
THRESH = 0.5

# 若你老师/题面强制要求“血管=0，其他=255”，把这个改成 True（但注意：官方RLE脚本是按>0当mask的）
INVERT_OUTPUT_MASK = False

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

def seed_everything(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)

# ----------------------------
# 1. Direct dataset paths (Kaggle Input) + auto find script
# ----------------------------
DATASET_DIR = "/kaggle/input/mltask5"

SEG_ROOT = os.path.join(DATASET_DIR, "segmentation")
TRAIN_IMG_DIR = os.path.join(SEG_ROOT, "train", "image")
TRAIN_MSK_DIR = os.path.join(SEG_ROOT, "train", "label")
TEST_IMG_DIR  = os.path.join(SEG_ROOT, "test", "image")

# 自动搜索脚本位置（不管它在根目录还是在 segmentation 里都能找到）
script_cands = glob.glob(os.path.join(DATASET_DIR, "**", "segmentation_to_csv.py"), recursive=True)
SCRIPT_PATH = script_cands[0] if len(script_cands) > 0 else None

print("TRAIN_IMG_DIR:", TRAIN_IMG_DIR)
print("TRAIN_MSK_DIR:", TRAIN_MSK_DIR)
print("TEST_IMG_DIR :", TEST_IMG_DIR)
print("SCRIPT candidates:", script_cands)
print("SCRIPT_PATH:", SCRIPT_PATH)

assert os.path.exists(TRAIN_IMG_DIR), "TRAIN_IMG_DIR 不存在"
assert os.path.exists(TRAIN_MSK_DIR), "TRAIN_MSK_DIR 不存在"
assert os.path.exists(TEST_IMG_DIR),  "TEST_IMG_DIR 不存在"
# 不要 assert SCRIPT_PATH，找不到就走我们自带的RLE fallback

# ----------------------------
# 2. File list
# ----------------------------
def sort_key(p):
    # 按文件名数字排序：1.jpg, 2.jpg, ...
    b = os.path.splitext(os.path.basename(p))[0]
    return int(b) if b.isdigit() else b

train_images = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, "*.*")), key=sort_key)
train_masks  = sorted(glob.glob(os.path.join(TRAIN_MSK_DIR, "*.*")), key=sort_key)
test_images  = sorted(glob.glob(os.path.join(TEST_IMG_DIR,  "*.*")), key=sort_key)

assert len(train_images) == len(train_masks), "train image/mask 数量不匹配"
print(f"train: {len(train_images)}  test: {len(test_images)}")

# ----------------------------
# 3. Dataset + simple augment
# ----------------------------
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)
IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)

def random_augment(img, msk):
    # img: HWC RGB, uint8
    # msk: HW,  uint8 (0/255 or any)
    if random.random() < 0.5:
        img = img[:, ::-1, :]
        msk = msk[:, ::-1]
    if random.random() < 0.5:
        img = img[::-1, :, :]
        msk = msk[::-1, :]

    # 0/90/180/270 rotate
    k = random.randint(0, 3)
    if k:
        img = np.rot90(img, k).copy()
        msk = np.rot90(msk, k).copy()

    # brightness/contrast
    if random.random() < 0.5:
        alpha = 1.0 + (random.random() * 0.4 - 0.2)  # 0.8~1.2
        beta  = random.randint(-15, 15)
        img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

    return img, msk

class FundusSegDataset(Dataset):
    def __init__(self, img_paths, msk_paths=None, augment=False):
        self.img_paths = img_paths
        self.msk_paths = msk_paths
        self.augment = augment

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)

        if self.msk_paths is not None:
            msk_path = self.msk_paths[idx]
            msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)
            msk = cv2.resize(msk, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)

            if self.augment:
                img, msk = random_augment(img, msk)

            # jpg标注可能有压缩灰度，阈值化成0/1
            msk = (msk > 127).astype(np.float32)

            # normalize
            img = img.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))  # CHW

            return torch.tensor(img, dtype=torch.float32), torch.tensor(msk[None, ...], dtype=torch.float32)

        else:
            # test
            img = img.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))
            return torch.tensor(img, dtype=torch.float32), os.path.basename(img_path)

# ----------------------------
# 4. UNet model (pure torch, no torchvision dependency)
# ----------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.net(x)

class Down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.pool = nn.MaxPool2d(2)
        self.conv = DoubleConv(in_ch, out_ch)

    def forward(self, x):
        return self.conv(self.pool(x))

class Up(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False)
        self.conv = DoubleConv(in_ch, out_ch)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # pad to same size
        diffY = x2.size(2) - x1.size(2)
        diffX = x2.size(3) - x1.size(3)
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, in_ch=3, out_ch=1, base=32):
        super().__init__()
        self.inc = DoubleConv(in_ch, base)
        self.down1 = Down(base, base*2)
        self.down2 = Down(base*2, base*4)
        self.down3 = Down(base*4, base*8)
        self.down4 = Down(base*8, base*16)

        self.up1 = Up(base*16 + base*8, base*8)
        self.up2 = Up(base*8 + base*4, base*4)
        self.up3 = Up(base*4 + base*2, base*2)
        self.up4 = Up(base*2 + base, base)

        self.outc = nn.Conv2d(base, out_ch, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        x = self.up1(x5, x4)
        x = self.up2(x,  x3)
        x = self.up3(x,  x2)
        x = self.up4(x,  x1)
        return self.outc(x)

# ----------------------------
# 5. Loss & metric
# ----------------------------
def dice_coeff_from_logits(logits, targets, eps=1e-6):
    probs = torch.sigmoid(logits)
    probs = (probs > THRESH).float()
    targets = (targets > 0.5).float()
    inter = (probs * targets).sum(dim=(2,3))
    union = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)
    return dice.mean().item()

def soft_dice_loss_with_logits(logits, targets, eps=1e-6):
    probs = torch.sigmoid(logits)
    targets = targets.float()
    inter = (probs * targets).sum(dim=(2,3))
    union = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)
    return 1 - dice.mean()

bce = nn.BCEWithLogitsLoss()

# ----------------------------
# 6. Train / Val loop
# ----------------------------
def train_one_epoch(model, loader, optimizer, scaler=None):
    model.train()
    total_loss = 0.0
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)

        optimizer.zero_grad(set_to_none=True)

        if scaler is not None:
            with torch.cuda.amp.autocast():
                logits = model(imgs)
                loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            logits = model(imgs)
            loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
            loss.backward()
            optimizer.step()

        total_loss += loss.item() * imgs.size(0)

    return total_loss / len(loader.dataset)

@torch.no_grad()
def validate(model, loader):
    model.eval()
    dices = []
    total_loss = 0.0
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)
        logits = model(imgs)
        loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
        total_loss += loss.item() * imgs.size(0)
        dices.append(dice_coeff_from_logits(logits, masks))
    return total_loss / len(loader.dataset), float(np.mean(dices))

# ----------------------------
# 7. K-Fold training
# ----------------------------
from sklearn.model_selection import KFold

kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)
fold_models = []

use_amp = torch.cuda.is_available()
print("AMP:", use_amp)

for fold, (tr_idx, va_idx) in enumerate(kf.split(train_images), 1):
    print(f"\n========== Fold {fold}/{FOLDS} ==========")
    tr_imgs = [train_images[i] for i in tr_idx]
    tr_msks = [train_masks[i]  for i in tr_idx]
    va_imgs = [train_images[i] for i in va_idx]
    va_msks = [train_masks[i]  for i in va_idx]

    train_ds = FundusSegDataset(tr_imgs, tr_msks, augment=True)
    val_ds   = FundusSegDataset(va_imgs, va_msks, augment=False)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

    model = UNet(base=32).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

    scaler = torch.cuda.amp.GradScaler() if use_amp else None

    best_dice = -1.0
    best_path = f"/kaggle/working/unet_fold{fold}.pt"

    for epoch in range(1, EPOCHS+1):
        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler)
        va_loss, va_dice = validate(model, val_loader)
        scheduler.step()

        if va_dice > best_dice:
            best_dice = va_dice
            torch.save(model.state_dict(), best_path)

        if epoch % 10 == 0 or epoch == 1:
            print(f"Epoch {epoch:03d} | tr_loss {tr_loss:.4f} | va_loss {va_loss:.4f} | va_dice {va_dice:.4f} | best {best_dice:.4f}")

    fold_models.append(best_path)

print("\nBest models:", fold_models)

# ----------------------------
# 8. Inference (ensemble + simple TTA)
# ----------------------------
@torch.no_grad()
def predict_with_tta(model, imgs):
    # imgs: (B,3,H,W)
    model.eval()
    p0 = torch.sigmoid(model(imgs))

    # hflip
    p1 = torch.sigmoid(model(torch.flip(imgs, dims=[3])))
    p1 = torch.flip(p1, dims=[3])

    # vflip
    p2 = torch.sigmoid(model(torch.flip(imgs, dims=[2])))
    p2 = torch.flip(p2, dims=[2])

    # hvflip
    p3 = torch.sigmoid(model(torch.flip(imgs, dims=[2,3])))
    p3 = torch.flip(p3, dims=[2,3])

    return (p0 + p1 + p2 + p3) / 4.0

test_ds = FundusSegDataset(test_images, msk_paths=None, augment=False)
test_loader = DataLoader(test_ds, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)

# accumulate probs
all_names = []
all_probs = []

# prepare accumulator in dict by name
prob_dict = {}

for model_path in fold_models:
    model = UNet(base=32).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    for imgs, names in tqdm(test_loader, desc=f"Predict {os.path.basename(model_path)}"):
        imgs = imgs.to(device)
        probs = predict_with_tta(model, imgs).detach().cpu().numpy()  # (B,1,H,W)
        for i, n in enumerate(names):
            if n not in prob_dict:
                prob_dict[n] = probs[i,0]
            else:
                prob_dict[n] += probs[i,0]

# average over folds
for n in prob_dict:
    prob_dict[n] /= len(fold_models)

# ----------------------------
# 9. Save predicted masks to ./image (for official script)
# ----------------------------
out_img_dir = "/kaggle/working/image"
os.makedirs(out_img_dir, exist_ok=True)

for img_path in test_images:
    name = os.path.basename(img_path)  # e.g. 1.jpg
    stem = os.path.splitext(name)[0]
    prob = prob_dict[name]

    mask = (prob > THRESH).astype(np.uint8) * 255  # vessel=255
    if INVERT_OUTPUT_MASK:
        mask = 255 - mask

    save_path = os.path.join(out_img_dir, f"{stem}.png")
    cv2.imwrite(save_path, mask)

print("Saved predicted masks to:", out_img_dir)
print("Example saved files:", sorted(glob.glob(out_img_dir+"/*.png"))[:5])

# ----------------------------
# 10. Make submission.csv (prefer official script; fallback to our own RLE)
# ----------------------------
def rle_encode_from_mask_binary(mask_01):
    # mask_01: HxW, values in {0,1}, flatten row-major
    dots = np.where(mask_01.flatten() == 1)[0]
    if len(dots) == 0:
        return ""
    run_lengths = []
    prev = -2
    for b in dots:
        if b > prev + 1:
            run_lengths.extend((b + 1, 0))  # 1-indexed
        run_lengths[-1] += 1
        prev = b
    return " ".join(map(str, run_lengths))

submission_path = "/kaggle/working/submission.csv"

# Try official script
ok = False
if os.path.exists(SCRIPT_PATH):
    try:
        # 把脚本拷到 working，避免路径问题
        import shutil
        shutil.copy(SCRIPT_PATH, "/kaggle/working/segmentation_to_csv.py")
        # 运行脚本（它默认读取 ./image 并输出 submission.csv）
        ret = os.system("cd /kaggle/working && python segmentation_to_csv.py")
        if ret == 0 and os.path.exists("/kaggle/working/submission.csv"):
            ok = True
            print("Official script generated submission.csv ✅")
    except Exception as e:
        print("Official script failed, fallback to custom RLE. Error:", e)

if not ok:
    print("Using custom RLE to generate submission.csv ...")
    rows = []
    for p in sorted(glob.glob(out_img_dir+"/*.png"), key=sort_key):
        stem = os.path.splitext(os.path.basename(p))[0]
        m = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
        m = cv2.resize(m, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
        m01 = (m > 0).astype(np.uint8)  # >0 as mask (same as official script)
        pred = rle_encode_from_mask_binary(m01)
        rows.append([stem, pred])
    df = pd.DataFrame(rows, columns=["Id", "Predicted"])
    df.to_csv(submission_path, index=False)
    print("Custom submission.csv generated ✅")

print("\nDone! You can submit:", submission_path)
print(pd.read_csv(submission_path).head())
