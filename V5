# ============================================================
# Task-5 Vessel Segmentation (Fundus)
# v1-style: Train UNet (KFold) -> Predict -> Save masks -> Run official script -> submission.csv
# Kaggle-ready, no extra pip
#
# Boosts:
# - G-channel CLAHE (keep RGB)
# - BCE pos_weight auto (imbalance)
# - OOF threshold search
# - Postprocess: FOV mask + remove small components
#
# Submission safety:
# - CLEAR /kaggle/working/image every run
# - SAVE PNG ONLY (no JPG)
# ============================================================

import os, glob, random, shutil
import numpy as np
import pandas as pd
import cv2
from tqdm.auto import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import KFold

# ----------------------------
# 0. Config
# ----------------------------
SEED = 42
IMG_SIZE = 512
BATCH_SIZE = 2
EPOCHS = 70
LR = 2e-4
FOLDS = 5

# initial threshold; will be replaced by OOF best threshold
THRESH = 0.5

# submission script uses (pixel > 0) as vessel -> for submission: vessel=255, background=0
INVERT_OUTPUT_MASK = False  # keep False for submission

# boosts toggles
USE_GREEN_CLAHE = True
USE_POS_WEIGHT  = True
USE_OOF_THRESH  = True
USE_FOV_POST    = True
USE_CC_FILTER   = True

# postprocess params (safe-ish defaults)
MIN_COMPONENT_AREA = 60      # remove tiny speckles; adjust 30~150
FOV_GRAY_THRESH = 15

NUM_WORKERS = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("device:", device)

def seed_everything(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)

# ----------------------------
# 1. Dataset paths (Kaggle Input) + find official script
# ----------------------------
DATASET_DIR = "/kaggle/input/mltask5"
if not os.path.exists(os.path.join(DATASET_DIR, "segmentation", "train", "image")):
    # fallback search
    for d in glob.glob("/kaggle/input/*"):
        if os.path.exists(os.path.join(d, "segmentation", "train", "image")):
            DATASET_DIR = d
            break

SEG_ROOT = os.path.join(DATASET_DIR, "segmentation")
TRAIN_IMG_DIR = os.path.join(SEG_ROOT, "train", "image")
TRAIN_MSK_DIR = os.path.join(SEG_ROOT, "train", "label")
TEST_IMG_DIR  = os.path.join(SEG_ROOT, "test",  "image")

script_cands = glob.glob(os.path.join(DATASET_DIR, "**", "segmentation_to_csv.py"), recursive=True)
SCRIPT_PATH = script_cands[0] if len(script_cands) > 0 else None

print("DATASET_DIR   :", DATASET_DIR)
print("TRAIN_IMG_DIR :", TRAIN_IMG_DIR)
print("TRAIN_MSK_DIR :", TRAIN_MSK_DIR)
print("TEST_IMG_DIR  :", TEST_IMG_DIR)
print("SCRIPT_PATH   :", SCRIPT_PATH)

assert os.path.exists(TRAIN_IMG_DIR), "TRAIN_IMG_DIR 不存在"
assert os.path.exists(TRAIN_MSK_DIR), "TRAIN_MSK_DIR 不存在"
assert os.path.exists(TEST_IMG_DIR),  "TEST_IMG_DIR 不存在"

# ----------------------------
# 2. File list
# ----------------------------
def sort_key(p):
    b = os.path.splitext(os.path.basename(p))[0]
    return int(b) if b.isdigit() else b

train_images = sorted(glob.glob(os.path.join(TRAIN_IMG_DIR, "*.*")), key=sort_key)
train_masks  = sorted(glob.glob(os.path.join(TRAIN_MSK_DIR, "*.*")), key=sort_key)
test_images  = sorted(glob.glob(os.path.join(TEST_IMG_DIR,  "*.*")), key=sort_key)

assert len(train_images) == len(train_masks), "train image/mask 数量不匹配"
print(f"train: {len(train_images)}  test: {len(test_images)}")

# ----------------------------
# 3. Preprocess / Augment
# ----------------------------
IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)
IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)

CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))

def fundus_preprocess_rgb(img_rgb):
    # keep RGB; only enhance green channel
    if not USE_GREEN_CLAHE:
        return img_rgb
    out = img_rgb.copy()
    out[:, :, 1] = CLAHE.apply(out[:, :, 1])
    return out

def random_augment(img, msk):
    if random.random() < 0.5:
        img = img[:, ::-1, :]
        msk = msk[:, ::-1]
    if random.random() < 0.5:
        img = img[::-1, :, :]
        msk = msk[::-1, :]

    k = random.randint(0, 3)
    if k:
        img = np.rot90(img, k).copy()
        msk = np.rot90(msk, k).copy()

    if random.random() < 0.5:
        alpha = 1.0 + (random.random() * 0.4 - 0.2)  # 0.8~1.2
        beta  = random.randint(-15, 15)
        img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

    return img, msk

def make_fov_mask_from_rgb(img_rgb, size=512, thr=15):
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)
    gray = cv2.resize(gray, (size, size), interpolation=cv2.INTER_AREA)
    _, m = cv2.threshold(gray, thr, 255, cv2.THRESH_BINARY)
    m = cv2.medianBlur(m, 7)
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, k)
    return (m > 0).astype(np.uint8)  # 0/1

def remove_small_components(mask01, min_area=60):
    # mask01: 0/1 uint8
    if min_area <= 0:
        return mask01
    num, labels, stats, _ = cv2.connectedComponentsWithStats(mask01.astype(np.uint8), connectivity=8)
    if num <= 1:
        return mask01
    keep = stats[:, cv2.CC_STAT_AREA] >= min_area
    keep[0] = False
    out01 = keep[labels].astype(np.uint8)
    return out01

# ----------------------------
# 4. Dataset
# ----------------------------
class FundusSegDataset(Dataset):
    def __init__(self, img_paths, msk_paths=None, augment=False):
        self.img_paths = img_paths
        self.msk_paths = msk_paths
        self.augment = augment

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)

        img = fundus_preprocess_rgb(img)

        if self.msk_paths is not None:
            msk_path = self.msk_paths[idx]
            msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)
            msk = cv2.resize(msk, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)

            if self.augment:
                img, msk = random_augment(img, msk)

            msk = (msk > 127).astype(np.float32)

            img = img.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))

            return torch.tensor(img, dtype=torch.float32), torch.tensor(msk[None, ...], dtype=torch.float32)

        else:
            img = img.astype(np.float32) / 255.0
            img = (img - IMAGENET_MEAN) / IMAGENET_STD
            img = np.transpose(img, (2, 0, 1))
            return torch.tensor(img, dtype=torch.float32), os.path.basename(img_path)

# ----------------------------
# 5. UNet (same as v1)
# ----------------------------
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )
    def forward(self, x):
        return self.net(x)

class Down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.pool = nn.MaxPool2d(2)
        self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x):
        return self.conv(self.pool(x))

class Up(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.up = nn.Upsample(scale_factor=2, mode="bilinear", align_corners=False)
        self.conv = DoubleConv(in_ch, out_ch)
    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size(2) - x1.size(2)
        diffX = x2.size(3) - x1.size(3)
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, in_ch=3, out_ch=1, base=32):
        super().__init__()
        self.inc = DoubleConv(in_ch, base)
        self.down1 = Down(base, base*2)
        self.down2 = Down(base*2, base*4)
        self.down3 = Down(base*4, base*8)
        self.down4 = Down(base*8, base*16)

        self.up1 = Up(base*16 + base*8, base*8)
        self.up2 = Up(base*8 + base*4, base*4)
        self.up3 = Up(base*4 + base*2, base*2)
        self.up4 = Up(base*2 + base, base)

        self.outc = nn.Conv2d(base, out_ch, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        x = self.up1(x5, x4)
        x = self.up2(x,  x3)
        x = self.up3(x,  x2)
        x = self.up4(x,  x1)
        return self.outc(x)

# ----------------------------
# 6. Loss & metric
# ----------------------------
def soft_dice_loss_with_logits(logits, targets, eps=1e-6):
    probs = torch.sigmoid(logits)
    targets = targets.float()
    inter = (probs * targets).sum(dim=(2,3))
    union = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)
    return 1 - dice.mean()

@torch.no_grad()
def dice_coeff_from_logits(logits, targets, thr=0.5, eps=1e-6):
    probs = torch.sigmoid(logits)
    pred = (probs > thr).float()
    gt = (targets > 0.5).float()
    inter = (pred * gt).sum(dim=(2,3))
    union = pred.sum(dim=(2,3)) + gt.sum(dim=(2,3))
    dice = (2*inter + eps) / (union + eps)
    return dice.mean().item()

# auto pos_weight for BCE
def compute_pos_weight(mask_paths, sample_n=20):
    # read a subset (dataset is tiny anyway)
    pos = 0
    neg = 0
    for p in mask_paths[:sample_n]:
        m = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
        m = cv2.resize(m, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
        m01 = (m > 127).astype(np.uint8)
        pos += int(m01.sum())
        neg += int(m01.size - m01.sum())
    pos = max(pos, 1)
    w = neg / pos
    # clamp to avoid extreme gradients
    w = float(np.clip(w, 1.0, 12.0))
    return w

pos_w = 1.0
if USE_POS_WEIGHT:
    pos_w = compute_pos_weight(train_masks, sample_n=len(train_masks))
print("pos_weight (clamped):", pos_w)

bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_w], device=device))

# ----------------------------
# 7. Train / Val loop
# ----------------------------
def train_one_epoch(model, loader, optimizer, scaler=None):
    model.train()
    total_loss = 0.0
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)
        optimizer.zero_grad(set_to_none=True)

        if scaler is not None:
            with torch.cuda.amp.autocast():
                logits = model(imgs)
                loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
            scaler.scale(loss).backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()
        else:
            logits = model(imgs)
            loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

        total_loss += loss.item() * imgs.size(0)
    return total_loss / len(loader.dataset)

@torch.no_grad()
def validate(model, loader, thr=0.5):
    model.eval()
    total_loss = 0.0
    dices = []
    for imgs, masks in loader:
        imgs = imgs.to(device)
        masks = masks.to(device)
        logits = model(imgs)
        loss = 0.5*bce(logits, masks) + 0.5*soft_dice_loss_with_logits(logits, masks)
        total_loss += loss.item() * imgs.size(0)
        dices.append(dice_coeff_from_logits(logits, masks, thr=thr))
    return total_loss / len(loader.dataset), float(np.mean(dices))

# ----------------------------
# 8. K-Fold training
# ----------------------------
kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)
fold_models = []
fold_val_idx = []  # keep for OOF

use_amp = torch.cuda.is_available()
print("AMP:", use_amp)

for fold, (tr_idx, va_idx) in enumerate(kf.split(train_images), 1):
    print(f"\n========== Fold {fold}/{FOLDS} ==========")
    fold_val_idx.append(va_idx)

    tr_imgs = [train_images[i] for i in tr_idx]
    tr_msks = [train_masks[i]  for i in tr_idx]
    va_imgs = [train_images[i] for i in va_idx]
    va_msks = [train_masks[i]  for i in va_idx]

    train_ds = FundusSegDataset(tr_imgs, tr_msks, augment=True)
    val_ds   = FundusSegDataset(va_imgs, va_msks, augment=False)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)
    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

    model = UNet(base=32).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
    scaler = torch.cuda.amp.GradScaler() if use_amp else None

    best_dice = -1.0
    best_path = f"/kaggle/working/unet_fold{fold}.pt"

    for epoch in range(1, EPOCHS+1):
        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler)
        va_loss, va_dice = validate(model, val_loader, thr=0.5)  # fixed 0.5 for model selection
        scheduler.step()

        if va_dice > best_dice:
            best_dice = va_dice
            torch.save(model.state_dict(), best_path)

        if epoch % 10 == 0 or epoch == 1:
            print(f"Epoch {epoch:03d} | tr_loss {tr_loss:.4f} | va_loss {va_loss:.4f} | va_dice {va_dice:.4f} | best {best_dice:.4f}")

    fold_models.append(best_path)

print("\nBest models:", fold_models)

# ----------------------------
# 9. OOF threshold search (choose THRESH)
# ----------------------------
@torch.no_grad()
def predict_probs_on_loader(model, loader):
    model.eval()
    probs_list, gts_list = [], []
    for imgs, masks in loader:
        imgs = imgs.to(device)
        logits = model(imgs)
        probs = torch.sigmoid(logits).detach().cpu().numpy()[:, 0]  # (B,H,W)
        probs_list.append(probs)
        gts_list.append(masks.numpy()[:, 0])
    return np.concatenate(probs_list, 0), np.concatenate(gts_list, 0)

def dice_np(pred01, gt01, eps=1e-6):
    inter = (pred01 & gt01).sum(axis=(1,2))
    union = pred01.sum(axis=(1,2)) + gt01.sum(axis=(1,2))
    return float(((2*inter + eps) / (union + eps)).mean())

if USE_OOF_THRESH:
    print("\nOOF threshold search ...")
    all_probs = []
    all_gts = []

    for fold in range(1, FOLDS+1):
        va_idx = fold_val_idx[fold-1]
        va_imgs = [train_images[i] for i in va_idx]
        va_msks = [train_masks[i]  for i in va_idx]
        val_ds = FundusSegDataset(va_imgs, va_msks, augment=False)
        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

        m = UNet(base=32).to(device)
        m.load_state_dict(torch.load(fold_models[fold-1], map_location=device))
        probs, gts = predict_probs_on_loader(m, val_loader)

        all_probs.append(probs)
        all_gts.append(gts)

    all_probs = np.concatenate(all_probs, 0)
    all_gts = np.concatenate(all_gts, 0)

    best_t, best_d = 0.5, -1
    # tighter search range (more stable for small data)
    for t in np.linspace(0.35, 0.65, 61):
        pred01 = (all_probs > t).astype(np.uint8)
        gt01 = (all_gts > 0.5).astype(np.uint8)
        d = dice_np(pred01, gt01)
        if d > best_d:
            best_d, best_t = d, float(t)

    THRESH = best_t
    print(f"OOF best THRESH = {THRESH:.3f}, OOF dice = {best_d:.4f}")
else:
    print("\nSkip OOF threshold; THRESH =", THRESH)

# ----------------------------
# 10. Inference (ensemble + TTA)
# ----------------------------
@torch.no_grad()
def predict_with_tta(model, imgs):
    model.eval()
    p0 = torch.sigmoid(model(imgs))

    p1 = torch.sigmoid(model(torch.flip(imgs, dims=[3])))
    p1 = torch.flip(p1, dims=[3])

    p2 = torch.sigmoid(model(torch.flip(imgs, dims=[2])))
    p2 = torch.flip(p2, dims=[2])

    p3 = torch.sigmoid(model(torch.flip(imgs, dims=[2,3])))
    p3 = torch.flip(p3, dims=[2,3])

    return (p0 + p1 + p2 + p3) / 4.0

test_ds = FundusSegDataset(test_images, msk_paths=None, augment=False)
test_loader = DataLoader(test_ds, batch_size=2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

prob_dict = {}

for model_path in fold_models:
    model = UNet(base=32).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    for imgs, names in tqdm(test_loader, desc=f"Predict {os.path.basename(model_path)}"):
        imgs = imgs.to(device)
        probs = predict_with_tta(model, imgs).detach().cpu().numpy()  # (B,1,H,W)
        for i, n in enumerate(names):
            prob_dict[n] = prob_dict.get(n, 0.0) + probs[i, 0]

for n in prob_dict:
    prob_dict[n] /= len(fold_models)

# ----------------------------
# 11. Save predicted masks to ./image (PNG ONLY + clean dir)
# ----------------------------
out_img_dir = "/kaggle/working/image"
os.makedirs(out_img_dir, exist_ok=True)

# CRITICAL: clean old files to avoid duplicate Id
for p in glob.glob(out_img_dir + "/*"):
    try:
        os.remove(p)
    except:
        pass

SAVE_EXT = "png"  # FORCE PNG (avoid JPG compression noise)
print("Saving masks as PNG | THRESH:", THRESH, "| MIN_COMPONENT_AREA:", MIN_COMPONENT_AREA)

for img_path in test_images:
    name = os.path.basename(img_path)  # e.g. 1.jpg
    stem = os.path.splitext(name)[0]
    prob = prob_dict[name]

    # binarize
    mask01 = (prob > THRESH).astype(np.uint8)

    # postprocess
    if USE_FOV_POST:
        raw = cv2.imread(img_path, cv2.IMREAD_COLOR)
        raw = cv2.cvtColor(raw, cv2.COLOR_BGR2RGB)
        fov = make_fov_mask_from_rgb(raw, IMG_SIZE, thr=FOV_GRAY_THRESH)
        mask01 = mask01 * fov

    if USE_CC_FILTER:
        mask01 = remove_small_components(mask01, min_area=MIN_COMPONENT_AREA)

    # submission-safe: vessel=255, background=0
    mask = mask01 * 255
    if INVERT_OUTPUT_MASK:
        mask = 255 - mask  # do NOT use for submission

    cv2.imwrite(os.path.join(out_img_dir, f"{stem}.{SAVE_EXT}"), mask)

print("Saved predicted masks to:", out_img_dir)
print("Example saved files:", sorted(glob.glob(out_img_dir+"/*.png"))[:5])

# ----------------------------
# 12. Make submission.csv (prefer official script; fallback to custom RLE)
# ----------------------------
def rle_encode_from_mask_binary(mask_01):
    dots = np.where(mask_01.flatten() == 1)[0]
    if len(dots) == 0:
        return ""
    run_lengths = []
    prev = -2
    for b in dots:
        if b > prev + 1:
            run_lengths.extend((b + 1, 0))  # 1-indexed
        run_lengths[-1] += 1
        prev = b
    return " ".join(map(str, run_lengths))

submission_path = "/kaggle/working/submission.csv"
ok = False

if SCRIPT_PATH is not None and os.path.exists(SCRIPT_PATH):
    try:
        shutil.copy(SCRIPT_PATH, "/kaggle/working/segmentation_to_csv.py")
        ret = os.system("cd /kaggle/working && python segmentation_to_csv.py")
        if ret == 0 and os.path.exists(submission_path):
            ok = True
            print("Official script generated submission.csv ✅")
        else:
            print("Official script did not produce submission.csv -> fallback RLE")
    except Exception as e:
        print("Official script failed -> fallback RLE. Error:", e)

if not ok:
    print("Using custom RLE to generate submission.csv ...")
    rows = []
    for p in sorted(glob.glob(out_img_dir+"/*.png"), key=sort_key):
        stem = os.path.splitext(os.path.basename(p))[0]
        m = cv2.imread(p, cv2.IMREAD_GRAYSCALE)
        m = cv2.resize(m, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
        m01 = (m > 0).astype(np.uint8)
        rows.append([stem, rle_encode_from_mask_binary(m01)])
    df = pd.DataFrame(rows, columns=["Id", "Predicted"])
    df.to_csv(submission_path, index=False)
    print("Custom submission.csv generated ✅")

# sanity checks (avoid upload errors)
df = pd.read_csv(submission_path)
print("\nsubmission rows:", len(df), "| unique Id:", df["Id"].nunique())
assert df["Id"].is_unique, "Id 重复：检查 /kaggle/working/image 是否有同名多文件"
assert df["Id"].nunique() == len(test_images), "submission Id 数量与测试图数量不一致"
print(df.head())
print("\nDone! Submit:", submission_path)
